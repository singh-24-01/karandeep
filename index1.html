<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Emploi du temps ‚Äì Master MLSD & AMSD</title>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="styles.css">
</head>
<body>
   <canvas id="space" aria-hidden="true"></canvas>

  <!-- HEADER -->
  <header>
    <div class="wrap nav">
      <div class="brand"><div class="logo" aria-hidden="true"></div><div>Master <span style="color:var(--brand)">MLSD</span> & <span style="color:var(--brand-2)">AMSD</span></div></div>
      <nav class="links" aria-label="Navigation principale">
        <a href="#planning" class="active" data-section="planning">Planning</a>
        <a href="#calendar" data-section="calendar">Calendrier</a>
        <a href="#presentation" data-section="presentation">Pr√©sentation du Master</a>
        <a href="#terms" data-section="terms">Termes</a>
        <a href="#plan" data-section="plan">Plan</a>
    </nav>

      <div class="actions">
        <a class="btn" href="https://intranet.u-paris.fr/" target="_blank" rel="noopener">Intranet</a>
        <a class="btn" href="https://moodle.u-paris.fr/" target="_blank" rel="noopener">Moodle</a>
        
        <button class="btn" id="themeToggle" aria-label="Basculer le th√®me">üåì</button>
      </div>
    </div>
  </header>
  <!-- === Prochains cours : popover === -->
  <div id="next-popover" class="popover" hidden>
    <div class="popover-inner">
      <div class="popover-title">√Ä venir</div>
      <ul id="next-list" class="popover-list"></ul>
    </div>
  </div>
  <!-- MAIN -->
  <main class="wrap">
    <!-- PLANNING -->
    <section id="planning" class="reveal">
      <div class="card">
        <div class="pill"><span class="dot"></span> Prochain cours <span id="nextTitle" style="margin-left:6px; font-weight:800"></span></div>
        <h1 class="h1">Emploi du temps ‚Äì Semaine en cours</h1>


        <div class="widget">
          <div class="row">
            <div class="seg">
              <div class="view-toggle" role="tablist" aria-label="Type de vue">
                <button class="chip active" data-mode="WEEK" role="tab" aria-selected="true">Semaine</button>
                <button class="chip" data-mode="AGENDA" role="tab" aria-selected="false">Agenda</button>
                <button class="chip" data-mode="MONTH" role="tab" aria-selected="false">Mois</button>
              </div>
            </div>
            <div class="seg" style="text-align:right">
              <button class="btn" id="prevWeek" title="Semaine pr√©c√©dente">‚óÄ</button>
              <button class="btn" id="today" title="Aujourd'hui">Aujourd'hui</button>
              <button class="btn" id="nextWeek" title="Semaine suivante">‚ñ∂</button>
            </div>
          </div>
          <div class="row">
            <div class="seg kbd">Timezone : Europe/Paris</div>
            <div class="seg" style="text-align:right"><span class="kbd">D√©but du prochain cours dans</span> <span class="countdown" id="countdown">‚Äî</span></div>
          </div>
          <div class="calendar-shell reveal d2">
            <iframe id="gcal" class="cal" title="Google Calendar embedded"></iframe>
          </div>
          <p class="sub">Si le calendrier ne s'affiche pas correctement, <a href="https://docs.google.com/spreadsheets/d/1IhyeM39QryPrYvrWcEFiChPrkVHD4Sw3/edit?gid=51203610#gid=51203610" target="_blank" rel="noopener">consulte la version de secours</a>.</p>
        </div>
      </div>
    </section>

    <section id="calendar" class="reveal d2" hidden>
      <div class="card">
        <h2 class="h1">Calendrier de formation 2025‚Äì2026</h2>
        <img src="calendrier2025.png" alt="Calendrier MLSD FI & FA " style="width:100%; border-radius:14px; border:1px solid var(--card-border)"/>
        <p class="sub">Valable pour MLSD FI & FA (2025‚Äì2026).</p>
      </div>
    </section>

    <section id="presentation" class="reveal d2" hidden>
        <div class="card">
            <h2 class="h1">Pr√©sentation du Master</h2>
            <p class="sub">Document officiel 2024‚Äì2025.</p>

        <iframe
            src="M1_Presentation_Master_MLSD-AMSD-24-25-3.pdf"
            width="100%"
            height="600"
            style="border-radius:14px; border:1px solid var(--card-border)"
        ></iframe>

            <p style="margin-top:12px">
                <a class="btn" href="M1_Presentation_Master_MLSD-AMSD-24-25-3.pdf" target="_blank" rel="noopener">
                üìÑ T√©l√©charger le PDF
                </a>
            </p>
        </div>
    </section>

    <section id="terms" class="reveal d2" hidden>
  <div class="card">
    <h2 class="h1">Termes statistiques essentiels</h2>
    <div class="terms-filters">
  <button data-cat="all" class="active">üåê Tout</button>
  <button data-cat="stats">üìä Statistiques de base</button>
  <button data-cat="proba">üéØ Probabilit√©s</button>
  <button data-cat="regression">üìà R√©gression</button>
  <button data-cat="ml">ü§ñ Machine Learning</button>
  <button data-cat="algebra">üî¢ Alg√®bre lin√©aire</button>
</div>

    <div class="terms-search">
  <input id="termsSearch" type="search"
         placeholder="Rechercher un terme (ex : variance, Poisson, ROC)‚Ä¶"
         autocomplete="off" />
  <span class="kbd" id="termsCount"></span>
</div>
    <div class="terms-content">
      <p data-cat="stats"><strong>Variance :</strong> Mesure de la dispersion des donn√©es autour de la moyenne. Plus la variance est grande, plus les donn√©es sont dispers√©es.</p>

      <p data-cat="stats"><strong>Biais (Bias) :</strong> Diff√©rence entre la valeur attendue d'un estimateur et la vraie valeur d'un param√®tre. Un mod√®le biais√© peut manquer de pr√©cision.</p>

      <p data-cat="stats"><strong>√âcart-type (Standard Deviation) :</strong> Racine carr√©e de la variance. Il exprime la dispersion des donn√©es par rapport √† la moyenne dans la m√™me unit√© que les donn√©es.</p>

      <p data-cat="stats"><strong>Quartiles :</strong> Valeurs qui divisent un ensemble de donn√©es en quatre parties √©gales. Le premier quartile (Q1), la m√©diane (Q2), et le troisi√®me quartile (Q3).</p>

      <p data-cat="proba"><strong>Loi de Bernoulli :</strong> Loi de probabilit√© qui d√©crit une exp√©rience al√©atoire ayant deux issues possibles (succ√®s ou √©chec), avec une probabilit√© fixe de succ√®s.</p>

      <p data-cat="proba"><strong>Loi binomiale :</strong> G√©n√©ralisation de la loi de Bernoulli pour plusieurs essais ind√©pendants. Elle mod√©lise le nombre de succ√®s dans un nombre d'essais donn√©s.</p>

      <p data-cat="proba"><strong>Loi normale (Gaussian Distribution) :</strong> Distribution de probabilit√© sym√©trique en forme de cloche, caract√©ris√©e par la moyenne et l'√©cart-type. Tr√®s utilis√©e pour mod√©liser des ph√©nom√®nes naturels.</p>

      <p data-cat="proba"><strong>Loi de Poisson :</strong> Distribution de probabilit√© qui mod√©lise le nombre d'√©v√©nements se produisant dans un intervalle de temps ou d'espace, sous certaines conditions.</p>

      <p data-cat="stats"><strong>Esp√©rance math√©matique (Expected Value) :</strong> Moyenne pond√©r√©e des r√©sultats d'une variable al√©atoire. C'est la valeur centrale attendue d'une exp√©rience al√©atoire.</p>

      <p data-cat="proba"><strong>P-value :</strong> Probabilit√© de rejeter l'hypoth√®se nulle alors qu'elle est vraie. Utilis√©e dans les tests d'hypoth√®ses pour √©valuer la significativit√© statistique.</p>

      <p data-cat="stats"><strong>Intervalle de confiance (Confidence Interval) :</strong> Plage de valeurs qui, avec une certaine probabilit√©, contient la vraie valeur d'un param√®tre statistique.</p>

      <p data-cat="regression"><strong>R√©gression lin√©aire :</strong> Technique statistique utilis√©e pour mod√©liser la relation entre une variable d√©pendante et une ou plusieurs variables ind√©pendantes.</p>

      <p data-cat="ml"><strong>Surapprentissage (Overfitting) :</strong> Situation o√π un mod√®le est trop ajust√© aux donn√©es d'entra√Ænement, ce qui nuit √† sa g√©n√©ralisation sur des donn√©es nouvelles.</p>

      <p data-cat="ml"><strong>Sous-apprentissage (Underfitting) :</strong> Mod√®le trop simple pour capturer les relations sous-jacentes dans les donn√©es, conduisant √† une mauvaise performance.</p>

      <p data-cat="ml,stats"><strong>Matrice de confusion :</strong> Tableau utilis√© pour √©valuer la performance d'un mod√®le de classification en comptant les vraies et fausses pr√©dictions.</p>

      <p data-cat="stats"><strong>Test d'hypoth√®se :</strong> M√©thode statistique pour tester une affirmation sur un param√®tre de population en utilisant les donn√©es d'un √©chantillon.</p>

      <p data-cat="stats"><strong>Bootstrap :</strong> Technique de r√©√©chantillonnage qui permet d'estimer les propri√©t√©s d'un estimateur en r√©√©chantillonnant avec remplacement.</p>

      <p data-cat="stats"><strong>AIC/BIC :</strong> Crit√®res utilis√©s pour comparer diff√©rents mod√®les statistiques et choisir le meilleur mod√®le en fonction de sa qualit√© ajust√©e.</p>

      <p data-cat="ml,stats"><strong>Analyse en composantes principales (ACP) :</strong> M√©thode de r√©duction de dimensionnalit√© qui transforme des variables corr√©l√©es en nouvelles variables non corr√©l√©es tout en conservant l'essentiel de la variance.</p>

      <p data-cat="algebra"><strong>Matrice :</strong> Un tableau de nombres dispos√©s en lignes et en colonnes, utilis√© pour organiser des ensembles de donn√©es et des transformations lin√©aires.</p>

      <p data-cat="stats,algebra"><strong>Covariance :</strong> Mesure de la mani√®re dont deux variables varient ensemble. Si la covariance est positive, les deux variables augmentent ensemble, si elle est n√©gative, elles varient en sens inverse.</p>

      <p data-cat="algebra"><strong>Matrice de covariance :</strong> Matrice carr√©e qui pr√©sente les covariances entre chaque paire de variables dans un ensemble de donn√©es.</p>

      <p data-cat="algebra"><strong>Vecteur :</strong> Une liste ordonn√©e de nombres qui repr√©sente une quantit√© ayant une direction et une magnitude. Les vecteurs sont utilis√©s dans des espaces de haute dimension.</p>

      <p data-cat="algebra"><strong>Autovalues (Valeurs propres) :</strong> Les scalaires associ√©s aux vecteurs propres d'une matrice. Utilis√©es pour comprendre des caract√©ristiques fondamentales des transformations lin√©aires.</p>

      <p data-cat="algebra"><strong>Autovecteurs (Vecteurs propres) :</strong> Les vecteurs associ√©s aux valeurs propres qui ne changent pas de direction lors de la transformation par une matrice.</p>

      <p data-cat="regression"><strong>R√©gularisation :</strong> Technique utilis√©e pour ajouter une p√©nalit√© aux mod√®les statistiques afin d‚Äô√©viter le surapprentissage.</p>

      <p data-cat="regression"><strong>R√©gression Ridge :</strong> Forme de r√©gression lin√©aire qui inclut une r√©gularisation L2 pour p√©naliser les grands coefficients afin de r√©duire le surapprentissage.</p>

      <p data-cat="regression"><strong>R√©gression Lasso :</strong> Forme de r√©gression lin√©aire qui inclut une r√©gularisation L1 pour favoriser la parcimonie en for√ßant certains coefficients √† z√©ro.</p>

      <p data-cat="ml"><strong>Gradient Descent :</strong> Algorithme d'optimisation utilis√© pour minimiser la fonction de co√ªt dans les mod√®les d‚Äôapprentissage machine.</p>

      <p data-cat="stats"><strong>Matrice de corr√©lation :</strong> Une matrice qui montre la corr√©lation entre chaque paire de variables. Utile pour rep√©rer les relations lin√©aires entre les variables.</p>

      <p data-cat="proba"><strong>Loi des grands nombres :</strong> Th√©or√®me indiquant que, √† mesure que le nombre d'√©chantillons augmente, la moyenne d‚Äôun √©chantillon approche la moyenne th√©orique de la population.</p>

      <p data-cat="proba"><strong>Th√©or√®me central limite :</strong> Th√©or√®me stipulant que la somme ou la moyenne de variables al√©atoires ind√©pendantes tend vers une distribution normale √† mesure que la taille de l‚Äô√©chantillon augmente.</p>

      <p data-cat="stats"><strong>Maximum de vraisemblance (MLE) :</strong> M√©thode d‚Äôestimation des param√®tres d‚Äôun mod√®le statistique en maximisant une fonction de vraisemblance.</p>

      <p data-cat="ml"><strong>Algorithme K-means :</strong> Algorithme de clustering non supervis√© qui partitionne les donn√©es en k groupes en minimisant la distance intra-cluster.</p>

      <p data-cat="ml"><strong>R√©seaux bay√©siens :</strong> Structures de donn√©es en forme de graphe qui repr√©sentent les relations probabilistes entre des variables.</p>

      <p data-cat="ml"><strong>K-Nearest Neighbors (K-NN) :</strong> Algorithme utilis√© pour la classification bas√© sur la similarit√© des points voisins dans l'espace des donn√©es.</p>

      <p data-cat="algebra"><strong>Distance euclidienne :</strong> Mesure de la distance directe entre deux points dans un espace multi-dimensionnel. Utilis√©e dans les algorithmes de clustering.</p>

      <p data-cat="stats"><strong>Normalisation et standardisation :</strong> Techniques de pr√©traitement des donn√©es qui ram√®nent les donn√©es dans un intervalle fixe ou une distribution normalis√©e.</p>

      <p data-cat="stats"><strong>Test de Chi-carr√© :</strong> Test statistique utilis√© pour d√©terminer si une relation existe entre deux variables cat√©gorielles.</p>

      <p data-cat="regression"><strong>M√©thode des moindres carr√©s :</strong> M√©thode utilis√©e pour ajuster un mod√®le de r√©gression en minimisant la somme des carr√©s des diff√©rences entre les valeurs observ√©es et pr√©dites.</p>

      <p data-cat="stats"><strong>Variance expliqu√©e :</strong> Proportion de la variance totale d'un ensemble de donn√©es qui est expliqu√©e par un mod√®le statistique.</p>

      <p data-cat="stats"><strong>Effet de levier (Leverage) :</strong> Mesure de l'influence d'un point de donn√©es sur la r√©gression.</p>

      <p data-cat="stats"><strong>Information Entropy (Entropie) :</strong> Mesure de l'incertitude ou de la quantit√© d'information contenue dans une variable al√©atoire.</p>

      <p data-cat="stats"><strong>Mutual Information :</strong> Mesure de la d√©pendance entre deux variables, quantifiant combien conna√Ætre la valeur d'une variable r√©duit l'incertitude de l'autre.</p>

      <p data-cat="ml,stats"><strong>Cross-validation :</strong> Technique utilis√©e pour √©valuer la performance d‚Äôun mod√®le en le testant sur plusieurs sous-ensembles des donn√©es.</p>

      <p data-cat="ml"><strong>Random Forest :</strong> Algorithme bas√© sur la cr√©ation de multiples arbres de d√©cision pour am√©liorer la pr√©cision et r√©duire le risque de surapprentissage.</p>

      <p data-cat="ml"><strong>R√©seaux de neurones convolutifs (CNN) :</strong> Type de r√©seau de neurones sp√©cialis√© dans le traitement des donn√©es structur√©es en grille, comme les images.</p>

      <p data-cat="ml"><strong>R√©seaux de neurones r√©currents (RNN) :</strong> Type de r√©seau de neurones adapt√© aux s√©quences de donn√©es, o√π les informations des √©tapes pr√©c√©dentes influencent les pr√©dictions actuelles.</p>

      <p data-cat="ml"><strong>Courbe ROC (Receiver Operating Characteristic) :</strong> Courbe utilis√©e pour √©valuer les performances d'un mod√®le de classification en tra√ßant le taux de vrais positifs contre le taux de faux positifs.</p>

      <p data-cat="ml"><strong>AUC (Area Under the Curve) :</strong> Surface sous la courbe ROC, utilis√©e comme une mesure de performance globale d‚Äôun mod√®le de classification.</p>
    <p data-cat="ml"><strong>Batch Normalization :</strong> Technique utilis√©e dans les r√©seaux de neurones pour normaliser les activations d'une couche, acc√©l√©rant l'entra√Ænement et am√©liorant la stabilit√©.</p>

<p data-cat="ml"><strong>Dropout :</strong> M√©thode de r√©gularisation pour les r√©seaux de neurones consistant √† d√©sactiver al√©atoirement certains neurones pendant l'entra√Ænement afin de r√©duire le surapprentissage.</p>

<p data-cat="ml"><strong>Ensemble Learning :</strong> Technique combinant plusieurs mod√®les pour am√©liorer la performance globale, comme le bagging, boosting ou stacking.</p>

<p data-cat="ml"><strong>XGBoost :</strong> Impl√©mentation optimis√©e de gradient boosting tr√®s performante pour les t√¢ches de classification et de r√©gression.</p>

<p data-cat="ml"><strong>LightGBM :</strong> Biblioth√®que de gradient boosting optimis√©e pour les gros ensembles de donn√©es, d√©velopp√©e par Microsoft.</p>

<p data-cat="proba"><strong>Odds Ratio :</strong> Mesure statistique exprimant le rapport des chances d'un √©v√©nement entre deux groupes.</p>

<p data-cat="stats"><strong>Coefficient de corr√©lation de Pearson :</strong> Mesure lin√©aire de la relation entre deux variables quantitatives, variant entre -1 et +1.</p>

<p data-cat="stats"><strong>Coefficient de corr√©lation de Spearman :</strong> Mesure non param√©trique de corr√©lation bas√©e sur les rangs des donn√©es.</p>

<p data-cat="proba"><strong>Intervalle de cr√©dibilit√© :</strong> Intervalle estim√© dans lequel un param√®tre a une probabilit√© donn√©e de se trouver, utilis√© en statistique bay√©sienne.</p>

<p data-cat="proba"><strong>Bayes' Theorem :</strong> Formule permettant de calculer la probabilit√© conditionnelle d‚Äôun √©v√©nement √† partir d‚Äôinformations pr√©alables.</p>

<p data-cat="ml"><strong>Feature Engineering :</strong> Processus de cr√©ation, transformation et s√©lection des variables (features) pour am√©liorer la performance d‚Äôun mod√®le.</p>

<p data-cat="ml"><strong>One-Hot Encoding :</strong> Technique de transformation des variables cat√©gorielles en variables binaires utilisables par les algorithmes de machine learning.</p>

<p data-cat="ml"><strong>Word Embeddings :</strong> Repr√©sentations vectorielles des mots, comme Word2Vec ou GloVe, capturant les relations s√©mantiques entre mots.</p>

<p data-cat="stats"><strong>Test t de Student :</strong> Test statistique utilis√© pour comparer la moyenne de deux groupes et d√©terminer si la diff√©rence est significative.</p>

<p data-cat="stats"><strong>ANOVA (Analyse de la variance) :</strong> Test statistique permettant de comparer les moyennes de plusieurs groupes.</p>

<p data-cat="regression"><strong>R√©gression logistique :</strong> Mod√®le statistique utilis√© pour pr√©dire une variable binaire √† partir de variables explicatives.</p>

<p data-cat="regression"><strong>Elastic Net :</strong> Technique de r√©gression combinant les r√©gularisations L1 (Lasso) et L2 (Ridge).</p>

<p data-cat="stats"><strong>Valeur aberrante (Outlier) :</strong> Observation qui s'√©carte fortement des autres valeurs d'un jeu de donn√©es.</p>

<p data-cat="ml"><strong>SMOTE (Synthetic Minority Over-sampling Technique) :</strong> M√©thode de r√©√©chantillonnage synth√©tique pour √©quilibrer des classes d√©s√©quilibr√©es.</p>

<p data-cat="stats"><strong>Kurtosis (Aplatissement) :</strong> Mesure d√©crivant la forme de la distribution, en particulier la concentration des valeurs dans les queues.</p>

<p data-cat="stats"><strong>Skewness (Asym√©trie) :</strong> Mesure indiquant si une distribution est sym√©trique ou penche vers la gauche/droite.</p>

<p data-cat="proba"><strong>Markov Chain :</strong> Mod√®le stochastique d√©crivant une s√©quence d‚Äô√©v√©nements o√π la probabilit√© de chaque √©v√©nement ne d√©pend que de l‚Äô√©tat pr√©c√©dent.</p>
<p data-cat="ml"><strong>Gradient Boosting :</strong> M√©thode d‚Äôensemble qui construit des mod√®les de mani√®re s√©quentielle, chaque nouveau mod√®le corrigeant les erreurs des pr√©c√©dents.</p>

<p data-cat="ml"><strong>CatBoost :</strong> Biblioth√®que de gradient boosting optimis√©e pour les variables cat√©gorielles, d√©velopp√©e par Yandex.</p>

<p data-cat="ml"><strong>Bagging :</strong> Technique d‚Äôensemble qui entra√Æne plusieurs mod√®les ind√©pendamment sur des √©chantillons bootstrap√©s, puis agr√®ge leurs pr√©dictions.</p>

<p data-cat="ml"><strong>AdaBoost :</strong> M√©thode de boosting adaptatif qui pond√®re les erreurs pour se concentrer sur les exemples difficiles √† classer.</p>

<p data-cat="ml"><strong>Hyperparameter Tuning :</strong> Processus d‚Äôoptimisation des param√®tres d‚Äôun mod√®le pour am√©liorer ses performances (grid search, random search, bayesian optimization).</p>

<p data-cat="ml"><strong>Early Stopping :</strong> Technique d'arr√™t anticip√© de l'entra√Ænement d‚Äôun mod√®le lorsque la performance sur un jeu de validation cesse de s'am√©liorer.</p>

<p data-cat="proba"><strong>Distribution exponentielle :</strong> Distribution de probabilit√© continue utilis√©e pour mod√©liser le temps entre des √©v√©nements dans un processus de Poisson.</p>

<p data-cat="proba"><strong>Distribution Gamma :</strong> Distribution continue flexible utilis√©e en mod√©lisation statistique et en th√©orie des files d'attente.</p>

<p data-cat="proba"><strong>Distribution Beta :</strong> Distribution continue d√©finie sur [0,1], souvent utilis√©e pour mod√©liser des proportions et des probabilit√©s.</p>

<p data-cat="proba"><strong>Processus de Poisson :</strong> Mod√®le stochastique d√©crivant le nombre d‚Äô√©v√©nements se produisant dans un intervalle de temps fixe.</p>

<p data-cat="stats"><strong>Colin√©arit√© :</strong> Situation o√π deux ou plusieurs variables explicatives sont fortement corr√©l√©es, rendant l‚Äôestimation des coefficients instable.</p>

<p data-cat="stats"><strong>Multicolin√©arit√© :</strong> Forme extr√™me de colin√©arit√© impliquant plusieurs variables, pouvant affecter la robustesse des mod√®les lin√©aires.</p>

<p data-cat="stats"><strong>Analyse discriminante lin√©aire (LDA) :</strong> M√©thode de classification qui projette les donn√©es sur un espace de dimension r√©duite maximisant la s√©paration entre classes.</p>

<p data-cat="regression"><strong>R√©gression polynomiale :</strong> Extension de la r√©gression lin√©aire qui mod√©lise des relations non lin√©aires en introduisant des puissances des variables explicatives.</p>

<p data-cat="regression"><strong>R√©gression PLS (Partial Least Squares) :</strong> M√©thode adapt√©e aux donn√©es fortement corr√©l√©es et aux situations avec plus de variables que d‚Äôobservations.</p>

<p data-cat="algebra"><strong>Norme vectorielle :</strong> Mesure de la taille ou de la longueur d‚Äôun vecteur, comme les normes L1, L2 et L‚àû.</p>

<p data-cat="algebra"><strong>Produit scalaire :</strong> Op√©ration entre deux vecteurs donnant un nombre, repr√©sentant la projection d‚Äôun vecteur sur un autre.</p>

<p data-cat="algebra"><strong>Produit matriciel :</strong> Op√©ration qui combine deux matrices pour produire une troisi√®me, utilis√©e dans de nombreuses transformations lin√©aires.</p>

<p data-cat="algebra"><strong>D√©composition en valeurs singuli√®res (SVD) :</strong> Factorisation d‚Äôune matrice en trois matrices, utilis√©e pour la r√©duction de dimension et la compression.</p>

<p data-cat="ml"><strong>Apprentissage par transfert (Transfer Learning) :</strong> R√©utilisation d‚Äôun mod√®le pr√©-entra√Æn√© sur un probl√®me similaire pour acc√©l√©rer l‚Äôapprentissage sur un nouveau probl√®me.</p>

<p data-cat="ml"><strong>Apprentissage semi-supervis√© :</strong> Technique exploitant √† la fois des donn√©es √©tiquet√©es et non √©tiquet√©es pour am√©liorer les performances d‚Äôun mod√®le.</p>

<p data-cat="ml"><strong>Apprentissage auto-supervis√© :</strong> Technique o√π un mod√®le g√©n√®re ses propres labels √† partir des donn√©es brutes pour pr√©-entra√Æner ses repr√©sentations.</p>

<p data-cat="ml"><strong>GAN (Generative Adversarial Network) :</strong> Architecture de deep learning compos√©e d‚Äôun g√©n√©rateur et d‚Äôun discriminateur, utilis√©e pour cr√©er des donn√©es synth√©tiques r√©alistes.</p>

<p data-cat="ml"><strong>Autoencoder :</strong> R√©seau de neurones entra√Æn√© √† reconstruire ses entr√©es apr√®s les avoir compress√©es, utilis√© pour la r√©duction de dimension et la d√©tection d‚Äôanomalies.</p>

    </div>
  </div>
</section>
 <!-- Palette de commandes (‚åòK / Ctrl‚ÄëK) -->
<div id="cmdk" class="cmdk" role="dialog" aria-modal="true" hidden>
  <div class="cmdk-box">
    <input id="cmdk-input" type="search" placeholder="Rechercher (sections & termes)‚Ä¶" aria-label="Palette de commandes" />
    <ul id="cmdk-results" class="cmdk-results" role="listbox" aria-label="R√©sultats"></ul>
    <div class="cmdk-hint">‚Üë‚Üì pour naviguer ‚Ä¢ Entr√©e pour ouvrir ‚Ä¢ Tab pour auto‚Äëcompl√©ter ‚Ä¢ √âchap pour fermer</div>
  </div>
</div>

<!-- Zone toasts -->
<div id="toast-root" aria-live="polite" aria-atomic="true"></div>


    <section id="plan" class="reveal d2" hidden>
      <div class="card"><h2 class="h1">Plan du b√¢timent principal</h2><img src="Plan_salles.jpg" alt="Plan du b√¢timent principal" style="width:100%; border-radius:14px; border:1px solid var(--card-border)"></div>
    </section>

    <footer class="reveal d3">¬© SINGH 2025 ‚Äì 2026 ‚Ä¢ Universit√© Paris Cit√©</footer>
  </main>

  <script src="script.js"></script>
</body>
</html>
